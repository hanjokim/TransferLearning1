# -*- coding: utf-8 -*-
"""objdet for tl의 사본

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1setcfyK_vpZ00sPbwLb4wEqsBpf8L5-T

실행 모델과 이미지 디렉토리 결정
"""

MODEL_TYPE = 'best' # 'high', 'fast'
EXT_IMAGES_DIR = '/content/drive/0work/images/1024x768'
#EXT_IMAGES_DIR = '/content/drive/0work/images'
#EXT_IMAGES_DIR = '/content/drive/0work/images/crop'
#EXT_IMAGES_DIR = '/content/drive/0work/images/scimage'

"""colab gpu memory를 11GB이상 할당받았는지 점검.
못받으면 더 진행해도 소용없음. 할당받을 때까지 런타임 다시 시작 반복.
"""

printm_undefined = False
try:
  printm
except NameError:
  printm_undefined = True
  
if printm_undefined:
  # memory footprint support libraries/code
  !ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi
  !pip install gputil
  !pip install psutil
  !pip install humanize
  import psutil
  import humanize
  import os
  import GPUtil as GPU
  GPUs = GPU.getGPUs()
  # XXX: only one GPU on Colab and isn’t guaranteed
  gpu = GPUs[0]
  def printm():
    process = psutil.Process(os.getpid())
    print("Gen RAM Free: " + humanize.naturalsize( psutil.virtual_memory().available ), " | Proc size: " + humanize.naturalsize( process.memory_info().rss))
    print("GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))
printm()

"""구글 드라이브 권한 얻기"""

!apt-get install -y -qq software-properties-common python-software-properties module-init-tools
!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null
!apt-get update -qq 2>&1 > /dev/null
!apt-get -y install -qq google-drive-ocamlfuse fuse
from google.colab import auth
auth.authenticate_user()
from oauth2client.client import GoogleCredentials
creds = GoogleCredentials.get_application_default()
import getpass
!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL
vcode = getpass.getpass()
!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}

!ls -l /content

"""/content/datalab 존재 여부에 따라 auth 여부 체크가 가능할까? **나중에 확인해 볼 것**"""

!mkdir -p drive
!google-drive-ocamlfuse drive

"""**Clone tensorflow models**"""

!if [ ! -e models ]; then git clone https://github.com/tensorflow/models.git; fi
!if [ ! -e models ]; then echo "Still undetected"; else echo "detected"; fi

!ls
!ls sample_data

"""필요한 소프트웨어 설치"""

!apt-get install protobuf-compiler python-pil python-lxml python-tk

!pip install --user Cython
!pip install --user contextlib2
!pip install --user jupyter
!pip install --user matplotlib

"""모델 실행 홈 디렉토리로 이동"""

os.chdir('/content/models/research/object_detection')

os.getcwd()

"""protos 디렉토리에 있는 object detection proto 를 컴파일"""

os.path.exists('protos')

protos_list = os.listdir('protos')
if not 'model_pb2.py' in protos_list:
  !(cd ..; protoc object_detection/protos/*.proto --python_out=.)
'model_pb2.py' in os.listdir('protos')

"""패키지 읽어 오기"""

import numpy as np
import os
import six.moves.urllib as urllib
import sys
import tarfile
import tensorflow as tf
import zipfile

from collections import defaultdict
from io import StringIO

"""PYTHONPATH 환경 변수와 리눅스 PATH 설정"""

os.environ['PYTHONPATH'] += ':' + '/content/models' ':' + '/content/models/research' + ':' + '/content/models/research/object_detection'

os.environ['PYTHONPATH']

# This is needed since the notebook is stored in the object_detection folder.
sys.path.append("..") # /content/models/research
print(sys.path)
from object_detection.utils import ops as utils_ops

#if tf.__version__ < '1.4.0':
#  raise ImportError('Please upgrade your tensorflow installation to v1.4.* or later!')

from object_detection.utils import label_map_util

from object_detection.utils import visualization_utils as vis_util

from matplotlib import pyplot as plt
from PIL import Image

# This is needed to display the images.
# %matplotlib inline

# plt에서 이미지 보여줄 때 그리드 표시하지 않도록 설정
plt.rcParams["axes.grid"] = False

"""pretrained model 다운로드 설정"""

# What model to download.
# Go to https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md for other models
# http://download.tensorflow.org/models/object_detection/faster_rcnn_inception_resnet_v2_atrous_coco_2018_01_28.tar.gz is 
# http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_coco_2018_01_28.tar.gz is new one
# http://download.tensorflow.org/models/object_detection/faster_rcnn_resnet101_coco_2018_01_28.tar.gz is worth to try

# if MODEL_TYPE == 'fast':
# #MODEL_NAME = 'ssd_mobilenet_v1_coco_2017_11_17'
#   MODEL_NAME = 'ssd_mobilenet_v1_coco_2018_01_28' # new fast
# elif MODEL_TYPE == 'best':
#   MODEL_NAME = 'faster_rcnn_inception_resnet_v2_atrous_coco_2018_01_28' # best
# elif MODEL_TYPE == 'high':
#   MODEL_NAME = 'faster_rcnn_resnet101_coco_2018_01_28'
# else:
#   MODEL_TYPE = 'fast'
#   MODEL_NAME = 'ssd_mobilenet_v1_coco_2018_01_28'

# For strawberry
MODEL_TYPE = 'fast' # unused
MODEL_NAME = 'faster_rcnn_inception_resnet_v2_atrous_oid_2018_01_28'
# http://download.tensorflow.org/models/object_detection/faster_rcnn_inception_resnet_v2_atrous_oid_2018_01_28.tar.gz

MODEL_FILE = MODEL_NAME + '.tar.gz'
DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'

# Path to frozen detection graph. This is the actual model that is used for the object detection.
PATH_TO_CKPT = MODEL_NAME + '/frozen_inference_graph.pb'

## Need to separate coco and other dataset cases - swkim
# List of the strings that is used to add correct label for each box.
# PATH_TO_LABELS = os.path.join('data', 'mscoco_label_map.pbtxt')
# For strawberry
PATH_TO_LABELS = os.path.join('data', 'oid_bbox_trainable_label_map.pbtxt')

#NUM_CLASSES = 90 # mscoco 레이블은 90, 모델에 맞춰서 설정
NUM_CLASSES = 545 # https://github.com/tensorflow/models/blob/master/research/object_detection/data/oid_bbox_trainable_label_map.pbtxt

os.getcwd()

print(MODEL_TYPE, MODEL_NAME, PATH_TO_CKPT, PATH_TO_LABELS, NUM_CLASSES)

"""Uncomment below at the first run

---

모델 체크포인트 파일 다운로드
"""

os.path.isfile(PATH_TO_CKPT)

if not os.path.isfile(PATH_TO_CKPT):
  opener = urllib.request.URLopener()
  opener.retrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)
  tar_file = tarfile.open(MODEL_FILE)
  for file in tar_file.getmembers():
    file_name = os.path.basename(file.name)
    if 'frozen_inference_graph.pb' in file_name:
      tar_file.extract(file, os.getcwd())
os.path.isfile(PATH_TO_CKPT)

"""체크포인트에 맞춰 그래프 만들기"""

detection_graph = tf.Graph()
with detection_graph.as_default():
  od_graph_def = tf.GraphDef()
  with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:
    serialized_graph = fid.read()
    od_graph_def.ParseFromString(serialized_graph)
    tf.import_graph_def(od_graph_def, name='')

"""레이블 맵 만들기"""

label_map = label_map_util.load_labelmap(PATH_TO_LABELS)
categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)
category_index = label_map_util.create_category_index(categories)

"""딸기가 학습된 모델인지 확인"""

for cat in categories:
  if (cat['name'] == 'Strawberry'):
    print(cat)

def load_image_into_numpy_array(image):
  (im_width, im_height) = image.size
  return np.array(image.getdata()).reshape(
      (im_height, im_width, 3)).astype(np.uint8)

"""모델과 함께 다운로드된 테스트 이미지"""

# For the sake of simplicity we will use only 2 images:
# image1.jpg
# image2.jpg
# If you want to test the code with your images, just add path to the images to the TEST_IMAGE_PATHS.
PATH_TO_TEST_IMAGES_DIR = 'test_images'
TEST_IMAGE_PATHS = [ os.path.join(PATH_TO_TEST_IMAGES_DIR, 'image{}.jpg'.format(i)) for i in range(1, 3) ]

print(TEST_IMAGE_PATHS)

# Size, in inches, of the output images.
IMAGE_SIZE = (9, 6)
#IMAGE_SIZE = (12, 8)
#IMAGE_SIZE = (16, 12)

import time

"""single image용 함수
---

더 이상 안 쓰기로 함
"""

# if EXT_IMAGES_DIR == None: # 나중에 undefined check로 변경하자 - swkim
#   EXT_IMAGES_DIR = '/content/drive/0work/images'

# os.listdir(EXT_IMAGES_DIR)

# def run_inference_for_single_image(image, graph):
#   with graph.as_default():
#     with tf.Session() as sess:
#       # Get handles to input and output tensors
#       ops = tf.get_default_graph().get_operations()
#       all_tensor_names = {output.name for op in ops for output in op.outputs}
#       tensor_dict = {}
#       for key in [
#           'num_detections', 'detection_boxes', 'detection_scores',
#           'detection_classes', 'detection_masks'
#       ]:
#         tensor_name = key + ':0'
#         if tensor_name in all_tensor_names:
#           tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(
#               tensor_name)
#       if 'detection_masks' in tensor_dict:
#         # The following processing is only for single image
#         detection_boxes = tf.squeeze(tensor_dict['detection_boxes'], [0])
#         detection_masks = tf.squeeze(tensor_dict['detection_masks'], [0])
#         # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.
#         real_num_detection = tf.cast(tensor_dict['num_detections'][0], tf.int32)
#         detection_boxes = tf.slice(detection_boxes, [0, 0], [real_num_detection, -1])
#         detection_masks = tf.slice(detection_masks, [0, 0, 0], [real_num_detection, -1, -1])
#         detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(
#             detection_masks, detection_boxes, image.shape[0], image.shape[1])
#         detection_masks_reframed = tf.cast(
#             tf.greater(detection_masks_reframed, 0.5), tf.uint8)
#         # Follow the convention by adding back the batch dimension
#         tensor_dict['detection_masks'] = tf.expand_dims(
#             detection_masks_reframed, 0)
#       image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')

#       start_time = time.time()
#       # Run inference
#       output_dict = sess.run(tensor_dict,
#                              feed_dict={image_tensor: np.expand_dims(image, 0)})
#       time_elapsed = time.time() - start_time
#       print("Inference time: %3.2f sec" % time_elapsed)

#       # all outputs are float32 numpy arrays, so convert types as appropriate
#       output_dict['num_detections'] = int(output_dict['num_detections'][0])
#       output_dict['detection_classes'] = output_dict[
#           'detection_classes'][0].astype(np.uint8)
#       output_dict['detection_boxes'] = output_dict['detection_boxes'][0]
#       output_dict['detection_scores'] = output_dict['detection_scores'][0]
#       if 'detection_masks' in output_dict:
#         output_dict['detection_masks'] = output_dict['detection_masks'][0]
#   return output_dict

# for image_path in TEST_IMAGE_PATHS:
#   print("processing %s" % os.path.basename(image_path))
#   total_start = time.time()
#   image = Image.open(image_path)
#   # the array based representation of the image will be used later in order to prepare the
#   # result image with boxes and labels on it.
#   image_np = load_image_into_numpy_array(image)
#   # Expand dimensions since the model expects images to have shape: [1, None, None, 3]
#   image_np_expanded = np.expand_dims(image_np, axis=0)
#   # Actual detection.
#   output_dict = run_inference_for_single_image(image_np, detection_graph)
#   # Visualization of the results of a detection.
#   vis_util.visualize_boxes_and_labels_on_image_array(
#       image_np,
#       output_dict['detection_boxes'],
#       output_dict['detection_classes'],
#       output_dict['detection_scores'],
#       category_index,
#       instance_masks=output_dict.get('detection_masks'),
#       use_normalized_coordinates=True,
#       line_thickness=8)
#   total_time = time.time() - total_start
#   print("Total elapsed time except drawing: %3.2f" % total_time)
#   plt.figure(figsize=IMAGE_SIZE)
#   plt.imshow(image_np)

"""wkelongws's test code to dispatch nodes manually on **gpu and cpu**
---
https://github.com/tensorflow/models/issues/3270
"""

# # import numpy as np
# # import os
# # import sys

# # # This is needed since the notebook is stored in the object_detection folder.
# # sys.path.append("..")

# # import tensorflow as tf
# # import time
# import copy

# from tensorflow.core.framework import graph_pb2
# # from utils import label_map_util
# # from utils import visualization_utils as vis_util
# # from matplotlib import pyplot as plt
# # from PIL import Image


# def _node_name(n):
#   if n.startswith("^"):
#     return n[1:]
#   else:
#     return n.split(":")[0]


# input_graph = tf.Graph()
# with tf.Session(graph=input_graph):
#     score = tf.placeholder(tf.float32, shape=(None, 1917, 90), name="Postprocessor/convert_scores")
#     expand = tf.placeholder(tf.float32, shape=(None, 1917, 1, 4), name="Postprocessor/ExpandDims_1")
#     for node in input_graph.as_graph_def().node:
#         if node.name == "Postprocessor/convert_scores":
#             score_def = node
#         if node.name == "Postprocessor/ExpandDims_1":
#             expand_def = node


# detection_graph = tf.Graph()
# with detection_graph.as_default():
#   od_graph_def = tf.GraphDef()
#   with tf.gfile.GFile('./ssd_mobilenet_v1_coco_2017_11_17/frozen_inference_graph.pb', 'rb') as fid:
#     serialized_graph = fid.read()
#     od_graph_def.ParseFromString(serialized_graph)
#     dest_nodes = ['Postprocessor/convert_scores','Postprocessor/ExpandDims_1']

#     edges = {}
#     name_to_node_map = {}
#     node_seq = {}
#     seq = 0
#     for node in od_graph_def.node:
#       n = _node_name(node.name)
#       name_to_node_map[n] = node
#       edges[n] = [_node_name(x) for x in node.input]
#       node_seq[n] = seq
#       seq += 1

#     for d in dest_nodes:
#       assert d in name_to_node_map, "%s is not in graph" % d

#     nodes_to_keep = set()
#     next_to_visit = dest_nodes[:]
#     while next_to_visit:
#       n = next_to_visit[0]
#       del next_to_visit[0]
#       if n in nodes_to_keep:
#         continue
#       nodes_to_keep.add(n)
#       next_to_visit += edges[n]

#     nodes_to_keep_list = sorted(list(nodes_to_keep), key=lambda n: node_seq[n])

#     nodes_to_remove = set()
#     for n in node_seq:
#       if n in nodes_to_keep_list: continue
#       nodes_to_remove.add(n)
#     nodes_to_remove_list = sorted(list(nodes_to_remove), key=lambda n: node_seq[n])

#     keep = graph_pb2.GraphDef()
#     for n in nodes_to_keep_list:
#       keep.node.extend([copy.deepcopy(name_to_node_map[n])])

#     remove = graph_pb2.GraphDef()
#     remove.node.extend([score_def])
#     remove.node.extend([expand_def])
#     for n in nodes_to_remove_list:
#       remove.node.extend([copy.deepcopy(name_to_node_map[n])])

#     with tf.device('/gpu:0'):
#       tf.import_graph_def(keep, name='')
#     with tf.device('/cpu:0'):
#       tf.import_graph_def(remove, name='')

# with detection_graph.as_default():
#   with tf.Session(graph=detection_graph,config=tf.ConfigProto(allow_soft_placement=True)) as sess:
#     image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')
#     score_out = detection_graph.get_tensor_by_name('Postprocessor/convert_scores:0')
#     expand_out = detection_graph.get_tensor_by_name('Postprocessor/ExpandDims_1:0')
#     score_in = detection_graph.get_tensor_by_name('Postprocessor/convert_scores_1:0')
#     expand_in = detection_graph.get_tensor_by_name('Postprocessor/ExpandDims_1_1:0')
#     detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')
#     detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')
#     detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')
#     num_detections = detection_graph.get_tensor_by_name('num_detections:0')
#     i = 0
#     for _ in range(10):
#       image_path = TEST_IMAGE_PATHS[1]
#       i += 1
#       image = Image.open(image_path)
#       image_np = load_image_into_numpy_array(image)
#       image_np_expanded = np.expand_dims(image_np, axis=0)
    
#       start_time = time.time()
#       (score, expand) = sess.run([score_out, expand_out], feed_dict={image_tensor: image_np_expanded})
#       (boxes, scores, classes, num) = sess.run(
#             [detection_boxes, detection_scores, detection_classes, num_detections],
#             feed_dict={score_in:score, expand_in: expand})
#       print('Iteration %d: %.3f sec'%(i, time.time()-start_time))

#       vis_util.visualize_boxes_and_labels_on_image_array(
#         image_np,
#        np.squeeze(boxes),
#       np.squeeze(classes).astype(np.int32),
#       np.squeeze(scores),
#       category_index,
#       use_normalized_coordinates=True,
#       line_thickness=8)

#     plt.figure(figsize=IMAGE_SIZE)
#     plt.imshow(image_np)

"""dennywang's **multiple inference module**
---
https://github.com/dennywangtenk/balder/blob/master/inference_util.py
"""

# coding: utf-8

# # Object Detection Demo
### Please refer to https://github.com/tensorflow/models/blob/master/research/object_detection/object_detection_tutorial.ipynb
### In the DEMO notebook, there is a function run inference for single image.
###
### Added a new function for running inference for multiple images
###

## v1

import datetime
#import os
#import sys

# from collections import defaultdict
# from io import StringIO
# import numpy as np
# import tensorflow as tf
# from PIL import Image


def run_inference_for_images(images, graph):
    with graph.as_default():
        with tf.Session() as sess:
            output_dict_array = []

            for image in images:
                # Get handles to input and output tensors
                ops = tf.get_default_graph().get_operations()
                all_tensor_names = {output.name for op in ops for output in op.outputs}
                tensor_dict = {}
                for key in [
                    'num_detections', 'detection_boxes', 'detection_scores',
                    'detection_classes', 'detection_masks'
                ]:
                    tensor_name = key + ':0'
                    if tensor_name in all_tensor_names:
                        tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(
                            tensor_name)
                if 'detection_masks' in tensor_dict:
                    detection_boxes = tf.squeeze(tensor_dict['detection_boxes'], [0])
                    detection_masks = tf.squeeze(tensor_dict['detection_masks'], [0])
                    # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.
                    real_num_detection = tf.cast(tensor_dict['num_detections'][0], tf.int32)
                    detection_boxes = tf.slice(detection_boxes, [0, 0], [real_num_detection, -1])
                    detection_masks = tf.slice(detection_masks, [0, 0, 0], [real_num_detection, -1, -1])
                    detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(
                        detection_masks, detection_boxes, image.shape[0], image.shape[1])
                    detection_masks_reframed = tf.cast(
                        tf.greater(detection_masks_reframed, 0.5), tf.uint8)
                    # Follow the convention by adding back the batch dimension
                    tensor_dict['detection_masks'] = tf.expand_dims(
                        detection_masks_reframed, 0)
                image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')

                # Run inference
                start_time = time.time()
                output_dict = sess.run(tensor_dict,
                                       feed_dict={image_tensor: np.expand_dims(image, 0)})
                print("Inference time: %3.2f" % (time.time() - start_time))

                # all outputs are float32 numpy arrays, so convert types as appropriate
                output_dict['num_detections'] = int(output_dict['num_detections'][0])
                output_dict['detection_classes'] = output_dict[
                    'detection_classes'][0].astype(np.uint8)
                output_dict['detection_boxes'] = output_dict['detection_boxes'][0]
                output_dict['detection_scores'] = output_dict['detection_scores'][0]
                if 'detection_masks' in output_dict:
                    output_dict['detection_masks'] = output_dict['detection_masks'][0]

                output_dict_array.append(output_dict)

    return output_dict_array

category_index

###
### Refer to https://github.com/tensorflow/models/blob/master/research/object_detection/object_detection_tutorial.ipynb
###load your detection_graph
#detection_graph = tf.Graph()
#images = []
#### ...
####load your images
#### ...

# image_files = [ os.path.join(PATH_TO_TEST_IMAGES_DIR, '{}'.format(img)) for img in ['image1.jpg', 'image2.jpg'] ]
# images = []
# for img_file in image_files:  
#   image = Image.open(img_file)
#   image_np = load_image_into_numpy_array(image)
#   images.append(image_np)
#   #images.append(np.expand_dims(image_np, axis=0))

# print(images[0].shape)

# output_dict_array = run_inference_for_images(images,detection_graph)

# for idx in range(len(output_dict_array)):
#     output_dict = output_dict_array[idx]
#     image_np = images[idx]
#     vis_util.visualize_boxes_and_labels_on_image_array(
#         image_np,
#         output_dict['detection_boxes'],
#         output_dict['detection_classes'],
#         output_dict['detection_scores'],
#         category_index,
#         instance_masks=output_dict.get('detection_masks'),
#         use_normalized_coordinates=True,
#         line_thickness=6)
#     plt.figure(figsize=IMAGE_SIZE)
#     plt.imshow(image_np)
# ##
# ## show your images
# ## plt.imshow(image_np)
# ##

os.getcwd()

"""### mod for 12ships experiment"""

!ls /content/drive/0work/images/samples_12ships

EXT_IMAGES_DIR = '/content/drive/0work/images/samples_12ships'

import glob

if EXT_IMAGES_DIR == None:
  #EXT_IMAGES_DIR = '/content/drive/0work/images/crop' # images, images/crop, images/resized ??, ... 나중에 제일 위에서 선언, 또는 여기서 redefine? - swkim
  EXT_IMAGES_DIR = '/content/drive/0work/images/samples_12ships'
EXT_IMAGES_DIR

#EXT_IMAGES_DIR = '/content/drive/0work/images/scimage'

os.listdir(EXT_IMAGES_DIR)

image_files = glob.glob(EXT_IMAGES_DIR + '/*.jpg') + glob.glob(EXT_IMAGES_DIR + '/*.JPG')

EXT_TEST_LOCAL_DIR = '/content/drive/0work/images/samples_12ships/test_images2'
if not os.path.isdir(EXT_TEST_LOCAL_DIR):
  os.mkdir(EXT_TEST_LOCAL_DIR)

#!ls /content/drive/0work/images/crop/*.jpg 
os.listdir(EXT_TEST_LOCAL_DIR)

image_files

from shutil import copy, SameFileError

for file in image_files:
  print(file)
  try:
    copy(file, EXT_TEST_LOCAL_DIR)
  except SameFileError:
    print("Already exists: ", os.path.basename(file))
    pass

os.listdir(EXT_TEST_LOCAL_DIR)

image_files = glob.glob(EXT_TEST_LOCAL_DIR + '/*.jpg') + glob.glob(EXT_TEST_LOCAL_DIR + '/*.JPG')
image_files

images = []
for img_file in image_files:  
  print(img_file)
  image = Image.open(img_file)
  print('opened')
  image_np = load_image_into_numpy_array(image)
  print('numpied')
  images.append(image_np)
  print('appended', len(images), image_np.shape)
  #images.append(np.expand_dims(image_np, axis=0))

#print(images[0].shape)
#print(len(images))

images[0]

"""### initial infer : about 30 sec, next about 2 sec"""

output_dict_array = run_inference_for_images(images, detection_graph)

len(output_dict_array)

IMAGE_SIZE

# dict_len = len(output_dict)
# max_det = 10
# last_det = min(dict_len, max_det)
# print(last_det)
# print(output_dict['detection_scores'][:last_det])
# print(output_dict['detection_classes'][:last_det])
# cat_ind = output_dict['detection_classes'][0]
# print(category_index[cat_ind]['name'])

# print(len(output_dict))

# print(category_index[62]['name'])

# output_dict_array[0]

# output_dict['detection_scores'][0]

# change to 30 for best model, 10 for fast
#max_det = 10
max_det = 30

results = []
res_info = []

for idx in range(len(output_dict_array)):
    output_dict = output_dict_array[idx]
    image_np = images[idx]
    vis_util.visualize_boxes_and_labels_on_image_array(
        image_np,
        output_dict['detection_boxes'],
        output_dict['detection_classes'],
        output_dict['detection_scores'],
        category_index,
        instance_masks=output_dict.get('detection_masks'),
        use_normalized_coordinates=True,
        line_thickness=6)
    
    dict_len = len(output_dict['detection_classes'])
    #max_det = 10
    last_det = min(dict_len, max_det)
    print(last_det, output_dict['detection_scores'][:last_det], output_dict['detection_classes'][:last_det])
    title = []
    for cat_ind in range(last_det):
      cl_score = output_dict['detection_scores'][cat_ind]
      if cl_score > 0.5:
        class_id = output_dict['detection_classes'][cat_ind]
        #print("cat_ind: ", cat_ind, "class: ", class_id)
        cl_name = category_index[class_id]['name']
        title.append(cl_name + ':' + str(cl_score))

    results.append(image_np)
    res_info.append(title)
    fig = plt.figure(figsize=(24,16))
    #print("title: ", title, str(title))
    fig.suptitle(str(title), y=0.9, fontsize=12)
    plt.imshow(image_np)
    #fig.clf()

##
## show your images
#plt.imshow(res_images[0])
##



#SAVE_DIR = EXT_IMAGES_DIR + '/results0813' + '_' + MODEL_TYPE
SAVE_DIR = EXT_IMAGES_DIR + '/results0305' + '_' + MODEL_TYPE
if not os.path.isdir(SAVE_DIR):
  os.mkdir(SAVE_DIR)

os.listdir(SAVE_DIR)

cnt = 0
for im_np in results:
  im = Image.fromarray(im_np)
  im.save(SAVE_DIR + '/res_%02d.jpg' % cnt)
  cnt += 1

with open(SAVE_DIR + '/res_info.txt', 'w') as f:
  for i in range(len(res_info)):
    f.write('res_%02d.jpg: ' % i + str(res_info[i]) + '\n')

for i in range(len(res_info)):
  print("i: " + str(i) + ' ' + str(len(res_info[i])))

#l = ['person:0.9983292', 'person:0.9918291', 'person:0.9909306', 'person:0.9532275', 'person:0.93062764', 'person:0.85994977', 'person:0.8391501', 'tie:0.8173316', 'person:0.8055768', 'person:0.8046247', 'tv:0.6965783', 'person:0.5468236', 'person:0.5398523']

#len(l)

"""**여기부터 resized image test**"""

#EXT_IMAGES_DIR = '/content/drive/0work/images'
EXT_IMAGES_DIR = '/content/drive/0work/images/samples_12ships'

image_files = glob.glob(EXT_IMAGES_DIR + '/*.JPG')
image_files

from skimage.transform import resize, rotate

an_image_file = image_files[0]
an_image_file
an_image = Image.open(an_image_file)

an_image_np = load_image_into_numpy_array(an_image)

an_image_np

an_image_np.shape

plt.imshow(an_image_np)

an_image_sci_resized = resize(an_image_np, (768, 1024), preserve_range=True)

an_image_sci_resized

image_files

RESIZE_DIMS = (768, 1024) #aspect ratio를 어떻게할까?

images_resized = []
images_rotated = []
for img_file in image_files:  
  print(img_file)
  image = Image.open(img_file)
  print('opened')
  image_np = load_image_into_numpy_array(image)
  print('numpied')
#   h, w, c = image_np.shape
#   if h > w:
#     image_np = rotate(image_np, -90)
#     images_rotate.append(image_np)
#     print('rotated: ', img_file, ' ', image_np.shape)
  #bottle_resized = resize(bottle, (140, 54), anti_aliasing=True)
  image_np_resized = np.array(resize(image_np, RESIZE_DIMS, preserve_range=True), dtype=np.uint8)
  #image_np_resized = np.resize(image_np, RESIZE_DIMS)
  images_resized.append(image_np_resized)
  print('appended', len(images_resized), image_np_resized.shape)
  #images.append(np.expand_dims(image_np, axis=0))

#print(images[0].shape)
#print(len(images))

output_dict_array = run_inference_for_images(images_resized, detection_graph)

# change to 30 for best model, 10 for fast
#max_det = 10
max_det = 30

results = []
res_info = []

for idx in range(len(output_dict_array)):
    output_dict = output_dict_array[idx]
    image_np = images_resized[idx]
    vis_util.visualize_boxes_and_labels_on_image_array(
        image_np,
        output_dict['detection_boxes'],
        output_dict['detection_classes'],
        output_dict['detection_scores'],
        category_index,
        instance_masks=output_dict.get('detection_masks'),
        use_normalized_coordinates=True,
        line_thickness=4)
    
    dict_len = len(output_dict['detection_classes'])
    #max_det = 10
    last_det = min(dict_len, max_det)
    print(last_det, output_dict['detection_scores'][:last_det], output_dict['detection_classes'][:last_det])
    title = []
    for cat_ind in range(last_det):
      cl_score = output_dict['detection_scores'][cat_ind]
      if cl_score > 0.5:
        class_id = output_dict['detection_classes'][cat_ind]
        #print("cat_ind: ", cat_ind, "class: ", class_id)
        cl_name = category_index[class_id]['name']
        title.append(cl_name + ':' + str(cl_score))

    results.append(image_np)
    res_info.append(title)
    fig = plt.figure(figsize=(24,16))
    #print("title: ", title, str(title))
    fig.suptitle(str(title), y=0.9, fontsize=18)
    plt.imshow(image_np)
    #fig.clf()

##
## show your images
#plt.imshow(res_images[0])
##

SAVE_DIR = EXT_IMAGES_DIR + '/results0305_sci_resized' + '_' + MODEL_TYPE
if not os.path.isdir(SAVE_DIR):
  os.mkdir(SAVE_DIR)

os.listdir(SAVE_DIR)

cnt = 0
for im_np in results:
  im = Image.fromarray(im_np)
  im.save(SAVE_DIR + '/res_%02d.jpg' % cnt)
  cnt += 1

with open(SAVE_DIR + '/res_info.txt', 'w') as f:
  for i in range(len(res_info)):
    f.write('res_%02d.jpg: ' % i + str(res_info[i]) + '\n')

# CSV format
with open(SAVE_DIR + '/res_info.csv', 'w') as f:
  for i in range(len(res_info)):
    f.write('res_%02d.jpg, %3d, ' % (i, len(res_info[i])))
    for cand in res_info[i]:
      f.write(str(cand) + ', ')
    f.write('\n')